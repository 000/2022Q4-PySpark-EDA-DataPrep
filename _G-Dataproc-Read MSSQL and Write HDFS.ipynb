{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "Dataproc to MSSQL\n\nexport NUMWORKERS=2\n\nexport WORKER=n1-standard-8\n\nexport MASTER=n1-standard-8\n\ngcloud dataproc clusters create aekanun-datascience-1\u200a-\u200azone asia-east1-a\u200a-\u200amaster-machine-type=$MASTER\u200a-\u200aworker-machine-type=$WORKER\u200a-\u200anum-workers $NUMWORKERS\u200a-\u200ascopes cloud-platform\u200a-\u200abucket 'oct22\u201323'\u200a-\u200aproject bigdatainpractice1\u200a-\u200aregion asia-east1\u200a-\u200aproperties spark:spark.jars.packages=com.microsoft.azure:spark-mssql-connector:1.0.2\u200a-\u200aproperties spark:spark.driver.maxResultSize=50g\u200a-\u200aproperties spark:spark.driver.memory=58g\u200a-\u200aproperties spark:spark.executor-memory=1g\u200a-\u200amax-age 240m\u200a-\u200aimage-version=1.4-ubuntu18\u200a-\u200aenable-component-gateway\u200a-\u200aoptional-components=JUPYTER,ANACONDA\u200a-\u200aproperties 'spark:spark.yarn.executor.memoryOverhead = 8200'\u200a-\u200aproperties dataproc:dataproc.conscrypt.provider.enable=false"}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "server_name = \"jdbc:sqlserver://34.72.0.181\"\ndatabase_name = \"inclassdb\"\nurl = server_name + \";\" + \"databaseName=\" + database_name + \";\"\n\ntable_name = \"spark_flightdetail\"\nusername = \"SA\"\npassword = \"Passw0rd123456\" # Please specify password here"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": "read_result_df = spark.read.format(\"jdbc\")\\\n        .option(\"url\", url) \\\n        .option(\"dbtable\", table_name) \\\n        .option(\"user\", username) \\\n        .option(\"password\", password)\\\n        .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\").load()"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"data": {"text/plain": "70321"}, "execution_count": 3, "metadata": {}, "output_type": "execute_result"}], "source": "#read_result_df.count()"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": "read_result_df.write.parquet('/rawzone/')"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.13"}}, "nbformat": 4, "nbformat_minor": 2}